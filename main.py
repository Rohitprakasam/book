"""
BookForge 4.0 â€” Master Orchestrator
=====================================
Chains all four phases into a single end-to-end pipeline:

    Phase 1  Deconstruct   PDF â†’ tagged_manuscript.txt
    Phase 1b Style Extract PDF â†’ style_config.json
    Phase 2  Expand Swarm  chunks â†’ analyst â†’ drafter â†’ critic loop
    Phase 3  Art Dept      [ORIGINAL_ASSET] & [NEW_DIAGRAM] â†’ resolved Markdown
    Phase 4  Typesetting   Pandoc + Typst â†’ paginated PDF

Usage
-----
    python main.py "path/to/input.pdf" --style "path/to/style.pdf"
"""

from __future__ import annotations

import os
import sys
import uuid
import time
import argparse
from pathlib import Path

from dotenv import load_dotenv

load_dotenv()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CONFIGURATION
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
OUTPUT_DIR = Path("data/output")
EXPANDED_PATH = OUTPUT_DIR / "expanded_draft.md"
CHUNK_SEPARATOR = "\n\n--- CHUNK END ---\n\n"
THROTTLE_SECONDS = 5  # Reduced to 5s as per user request


def main(pdf_path: str, style_path: str = None) -> None:
    """Run the full BookForge 4.0 pipeline."""
    start_time = time.time()

    print()
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘          ðŸ“–  BOOKFORGE 4.0 â€” MASTER PIPELINE  ðŸ“–        â•‘")
    print("â•‘       Document Deconstruction & Reassembly Engine       â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # PHASE 1: THE DECONSTRUCTOR
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("â”" * 58)
    print("ðŸ”¬  PHASE 1 â€” THE DECONSTRUCTOR")
    print("â”" * 58)
    print(f"   Input PDF: {pdf_path}")
    
    # â”€â”€ Phase 1b: Style Extraction â”€â”€
    style_config = {}
    if style_path:
        print(f"   Style Ref: {style_path}")
        from src.style_manager import extract_style
        style_config = extract_style(style_path)
    else:
        print("   Style Ref: None (using defaults)")
    print()

    from src.deconstructor import deconstruct, MANUSCRIPT_PATH

    deconstruct(pdf_path)

    print(f"\n   âœ… Phase 1 complete â†’ {MANUSCRIPT_PATH}\n")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # PHASE 2: THE EXPANSION SWARM (with Throttle & Resume)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("â”" * 58)
    print("ðŸ  PHASE 2 â€” THE EXPANSION SWARM")
    print("â”" * 58)

    from src.chunker import chunk_manuscript
    from src.graph import build_graph

    chunks = chunk_manuscript(str(MANUSCRIPT_PATH))
    graph = build_graph()
    total = len(chunks)

    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    # â”€â”€ Resume Detection â”€â”€
    # If we crashed mid-run, pick up where we left off
    expanded_draft = ""
    start_chunk = 0

    if EXPANDED_PATH.exists():
        expanded_draft = EXPANDED_PATH.read_text(encoding="utf-8")
        start_chunk = expanded_draft.count("--- CHUNK END ---")
        if start_chunk > 0:
            print(f"   ðŸ”„ Found existing progress! Resuming from chunk {start_chunk + 1}â€¦")

    # â”€â”€ Thread Pool for Parallel PDF Generation â”€â”€
    from concurrent.futures import ThreadPoolExecutor
    from src.publisher import publish_chapter_pdf
    
    # We use a ThreadPoolExecutor to run PDF generation in the background
    # allowing the main loop to proceed to the next chunk immediately.
    pdf_executor = ThreadPoolExecutor(max_workers=3)

    if start_chunk < total:
        # â”€â”€ Main Expansion Loop â”€â”€
        for i, chunk in enumerate(chunks[start_chunk:], start=start_chunk):
            print(f"\n   â”€â”€ Chunk {i + 1}/{total} ({len(chunk):,} chars) â”€â”€")

            config = {"configurable": {"thread_id": str(uuid.uuid4())}}

            try:
                result = graph.invoke(
                    {"current_chunk": chunk, "revision_count": 0},
                    config,
                )
                expanded = result.get("expanded_chunk", chunk)
                print(f"   âœ… Chunk {i + 1} expanded â†’ {len(expanded):,} chars")
                
                # â”€â”€ Per-Chapter PDF Publishing (ASYNC) â”€â”€
                # Submit to thread pool instead of blocking
                print(f"   ðŸš€ Submitting Chapter {i + 1} to PDF generator (background)...")
                pdf_executor.submit(publish_chapter_pdf, expanded, i + 1)

            except Exception as e:
                print(f"   âš ï¸  Chunk {i + 1} failed: {e}")
                print("   â†³ Using original chunk as fallback")
                # Log error to file
                check_log = OUTPUT_DIR / "error_log.txt"
                check_log.parent.mkdir(parents=True, exist_ok=True)
                with open(check_log, "a", encoding="utf-8") as f:
                     f.write(f"\n[Chunk {i+1}] {str(e)}\n")
                expanded = chunk

            # â”€â”€ Checkpoint: save to disk after every chunk â”€â”€
            expanded_draft += expanded + CHUNK_SEPARATOR
            EXPANDED_PATH.write_text(expanded_draft, encoding="utf-8")
            print(f"   ðŸ’¾ Checkpoint saved to disk.")

            # â”€â”€ Throttle: wait between chunks to respect Groq rate limits â”€â”€
            if i < total - 1:
                print(f"   ðŸ›‘ Throttling for {THROTTLE_SECONDS}s (Groq rate-limit cooldown)â€¦")
                for remaining in range(THROTTLE_SECONDS, 0, -1):
                    print(f"\r      â³ Resuming in {remaining}sâ€¦  ", end="", flush=True)
                    time.sleep(1)
                print("\r      â–¶ï¸  Resuming!                  ")

        # â”€â”€ Cleanup: shutdown thread pool (wait for remaining PDFs) â”€â”€
        print("\n   â³ Waiting for pending PDF jobs to complete...")
        pdf_executor.shutdown(wait=True)
    
    else:
        print(f"\n   âœ… All {total} chunks already processed.")
        print("   â­ï¸  Skipping Expansion & Chapter PDF generation. Moving to Final Assembly.")

    # â”€â”€ Final expanded text (strip chunk markers for downstream use) â”€â”€
    full_expanded = expanded_draft.replace("--- CHUNK END ---", "---").strip()

    print(f"\n   âœ… Phase 2 complete â†’ {EXPANDED_PATH}")
    print(f"   ðŸ“Š {total} chunks expanded ({len(full_expanded):,} total chars)\n")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # PHASE 3: THE ART DEPARTMENT
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("â”" * 58)
    print("ðŸŽ¨  PHASE 3 â€” THE ART DEPARTMENT")
    print("â”" * 58)

    from src.resolver import process_art_department

    # Pass the style_config to the resolver
    process_art_department(full_expanded, style_config)

    print(f"\n   âœ… Phase 3 complete â†’ data/output/resolved_manuscript.md\n")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # PHASE 4: THE TYPESETTING ENGINE
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("â”" * 58)
    print("ðŸ–¨ï¸  PHASE 4 â€” THE TYPESETTING ENGINE")
    print("â”" * 58)

    from src.publisher import prepare_manuscript, publish_pdf

    prepare_manuscript()
    publish_pdf()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # SUMMARY
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    elapsed = time.time() - start_time
    minutes = int(elapsed // 60)
    seconds = int(elapsed % 60)

    print()
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘              ðŸŽ‰  BOOKFORGE COMPLETE  ðŸŽ‰                 â•‘")
    print("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
    print(f"â•‘  â±ï¸  Total time: {minutes}m {seconds}s")
    print(f"â•‘  ðŸ“„  Chunks processed: {total}")
    print(f"â•‘  ðŸ“  Expanded draft: {EXPANDED_PATH}")
    print(f"â•‘  ðŸ“–  Final PDF: data/output/BookForge_Final.pdf")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CLI ENTRY POINT
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="BookForge 4.0 Pipeline")
    parser.add_argument("pdf_input", help="Path to input PDF")
    parser.add_argument("--style", help="Path to Style Reference PDF", default=None)
    
    args = parser.parse_args()

    if not Path(args.pdf_input).exists():
        print(f"âŒ File not found: {args.pdf_input}")
        sys.exit(1)
        
    if args.style and not Path(args.style).exists():
        print(f"âš ï¸ Style file not found: {args.style}. Proceeding without style.")
        args.style = None

    main(args.pdf_input, args.style)
